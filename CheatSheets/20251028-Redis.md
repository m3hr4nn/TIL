# Redis Interview Cheat Sheet

## Core Concepts

**Redis**: Remote Dictionary Server - in-memory data structure store
**In-Memory**: Data stored in RAM for fast access
**Key-Value Store**: Data organized as key-value pairs
**Data Structures**: Strings, Lists, Sets, Sorted Sets, Hashes, Bitmaps, HyperLogLogs
**Persistence**: RDB snapshots and AOF (Append-Only File)
**Replication**: Master-slave architecture
**Pub/Sub**: Publish-subscribe messaging
**TTL**: Time To Live - automatic key expiration

## Data Types and Commands

### Strings
```bash
# Set key-value
SET user:1:name "John Doe"
SET counter 0

# Get value
GET user:1:name

# Set with expiration (seconds)
SETEX session:abc123 3600 "user_data"
SET session:xyz789 "data" EX 3600

# Set if not exists
SETNX lock:resource1 "locked"

# Increment/Decrement
INCR counter            # counter = 1
INCRBY counter 10       # counter = 11
DECR counter            # counter = 10

# Multiple operations
MSET user:1:name "John" user:1:age "30"
MGET user:1:name user:1:age

# Append
APPEND user:1:name " Smith"
```

### Hashes (Objects)
```bash
# Set hash fields
HSET user:1 name "John" age 30 email "john@example.com"
HSET user:1 name "John"

# Get hash field
HGET user:1 name

# Get all fields
HGETALL user:1

# Get multiple fields
HMGET user:1 name email

# Check if field exists
HEXISTS user:1 name

# Delete field
HDEL user:1 age

# Increment field
HINCRBY user:1 age 1

# Get all keys
HKEYS user:1

# Get all values
HVALS user:1
```

### Lists (Arrays/Queues)
```bash
# Push to list
LPUSH queue:tasks "task1"     # Left push
RPUSH queue:tasks "task2"     # Right push

# Pop from list
LPOP queue:tasks              # Left pop
RPOP queue:tasks              # Right pop

# Blocking pop (wait if empty)
BLPOP queue:tasks 10          # Wait 10 seconds

# Get range
LRANGE queue:tasks 0 -1       # All items
LRANGE queue:tasks 0 9        # First 10 items

# Get by index
LINDEX queue:tasks 0

# Length
LLEN queue:tasks

# Trim list
LTRIM queue:tasks 0 99        # Keep first 100 items

# Insert
LINSERT queue:tasks BEFORE "task2" "new_task"
```

### Sets (Unique Values)
```bash
# Add members
SADD tags:post1 "redis" "database" "nosql"

# Remove members
SREM tags:post1 "nosql"

# Check membership
SISMEMBER tags:post1 "redis"

# Get all members
SMEMBERS tags:post1

# Count members
SCARD tags:post1

# Random member
SRANDMEMBER tags:post1

# Pop random member
SPOP tags:post1

# Set operations
SINTER tags:post1 tags:post2    # Intersection
SUNION tags:post1 tags:post2    # Union
SDIFF tags:post1 tags:post2     # Difference
```

### Sorted Sets (Ordered by Score)
```bash
# Add members with scores
ZADD leaderboard 100 "player1"
ZADD leaderboard 200 "player2" 150 "player3"

# Get score
ZSCORE leaderboard "player1"

# Increment score
ZINCRBY leaderboard 10 "player1"

# Get rank
ZRANK leaderboard "player1"     # Ascending
ZREVRANK leaderboard "player1"  # Descending

# Get range by rank
ZRANGE leaderboard 0 9          # Top 10
ZREVRANGE leaderboard 0 9       # Top 10 descending

# Get range with scores
ZRANGE leaderboard 0 9 WITHSCORES

# Get range by score
ZRANGEBYSCORE leaderboard 100 200

# Count in range
ZCOUNT leaderboard 100 200

# Remove
ZREM leaderboard "player1"
```

## Key Management

```bash
# Check if key exists
EXISTS user:1

# Delete keys
DEL user:1
DEL user:1 user:2 user:3

# Set expiration
EXPIRE user:1 3600              # Seconds
EXPIREAT user:1 1735689600      # Unix timestamp
PEXPIRE user:1 3600000          # Milliseconds

# Get TTL
TTL user:1                      # Seconds remaining
PTTL user:1                     # Milliseconds

# Remove expiration
PERSIST user:1

# Rename key
RENAME oldkey newkey
RENAMENX oldkey newkey          # Only if newkey doesn't exist

# Get key type
TYPE user:1

# Find keys (avoid in production)
KEYS user:*
KEYS *

# Scan keys (better for production)
SCAN 0 MATCH user:* COUNT 100
```

## Advanced Features

### Transactions
```bash
# Start transaction
MULTI
SET user:1:name "John"
SET user:1:age 30
EXEC                            # Execute all

# Discard transaction
MULTI
SET user:1:name "John"
DISCARD

# Watch keys (optimistic locking)
WATCH user:1:balance
MULTI
DECRBY user:1:balance 100
EXEC                            # Fails if balance changed
```

### Pub/Sub
```bash
# Subscribe to channel
SUBSCRIBE news
SUBSCRIBE news sports tech

# Subscribe to pattern
PSUBSCRIBE news:*

# Publish message
PUBLISH news "Breaking news!"

# Unsubscribe
UNSUBSCRIBE news
```

### Lua Scripting
```bash
# Execute Lua script
EVAL "return redis.call('SET', KEYS[1], ARGV[1])" 1 mykey myvalue

# Atomic rate limiting script
EVAL "
local current = redis.call('INCR', KEYS[1])
if current == 1 then
    redis.call('EXPIRE', KEYS[1], ARGV[1])
end
return current
" 1 rate:limit:user123 60

# Load script
SCRIPT LOAD "return redis.call('GET', KEYS[1])"
# Returns SHA1 hash

# Execute loaded script
EVALSHA <sha1> 1 mykey
```

### Streams (Log/Event Store)
```bash
# Add to stream
XADD events * user "john" action "login"
XADD events * user "jane" action "logout"

# Read from stream
XREAD COUNT 10 STREAMS events 0

# Read new messages only
XREAD COUNT 10 BLOCK 5000 STREAMS events $

# Consumer groups
XGROUP CREATE events group1 0
XREADGROUP GROUP group1 consumer1 COUNT 10 STREAMS events >

# Acknowledge message
XACK events group1 <message-id>
```

## Persistence

### RDB (Snapshots)
```bash
# Manual snapshot
SAVE                            # Blocking
BGSAVE                          # Background

# Configuration (redis.conf)
save 900 1                      # Save after 900s if 1 key changed
save 300 10                     # Save after 300s if 10 keys changed
save 60 10000                   # Save after 60s if 10000 keys changed
```

### AOF (Append-Only File)
```bash
# Configuration (redis.conf)
appendonly yes
appendfsync everysec            # Write to disk every second
appendfsync always              # Write after every command (slow)
appendfsync no                  # Let OS decide

# Rewrite AOF
BGREWRITEAOF
```

## Replication

### Master-Slave Setup
```bash
# On slave
REPLICAOF master-host 6379
# or in redis.conf
replicaof master-host 6379

# Check replication status
INFO replication

# Stop replication
REPLICAOF NO ONE

# Read-only slave (default)
replica-read-only yes
```

## Caching Patterns

### Cache-Aside (Lazy Loading)
```python
def get_user(user_id):
    # Try cache first
    user = redis.get(f"user:{user_id}")
    if user:
        return json.loads(user)
    
    # Cache miss - fetch from database
    user = db.query("SELECT * FROM users WHERE id = ?", user_id)
    
    # Store in cache
    redis.setex(f"user:{user_id}", 3600, json.dumps(user))
    
    return user
```

### Write-Through
```python
def update_user(user_id, data):
    # Update database
    db.update("users", user_id, data)
    
    # Update cache
    redis.setex(f"user:{user_id}", 3600, json.dumps(data))
```

### Write-Behind (Write-Back)
```python
def update_user_async(user_id, data):
    # Update cache immediately
    redis.setex(f"user:{user_id}", 3600, json.dumps(data))
    
    # Queue for async DB write
    redis.lpush("write_queue", json.dumps({
        "table": "users",
        "id": user_id,
        "data": data
    }))
```

## Common Use Cases

### Session Storage
```python
import redis
import uuid
import json

redis_client = redis.Redis(host='localhost', port=6379, db=0)

# Create session
def create_session(user_id):
    session_id = str(uuid.uuid4())
    session_data = {
        'user_id': user_id,
        'created_at': time.time()
    }
    redis_client.setex(
        f"session:{session_id}",
        3600,  # 1 hour
        json.dumps(session_data)
    )
    return session_id

# Get session
def get_session(session_id):
    data = redis_client.get(f"session:{session_id}")
    return json.loads(data) if data else None
```

### Rate Limiting
```python
def rate_limit(user_id, max_requests=100, window=60):
    key = f"rate_limit:{user_id}"
    current = redis_client.incr(key)
    
    if current == 1:
        redis_client.expire(key, window)
    
    if current > max_requests:
        return False  # Rate limit exceeded
    
    return True
```

### Leaderboard
```python
# Update score
redis_client.zincrby("leaderboard", 10, "player123")

# Get top 10
top_players = redis_client.zrevrange("leaderboard", 0, 9, withscores=True)

# Get player rank
rank = redis_client.zrevrank("leaderboard", "player123")

# Get score
score = redis_client.zscore("leaderboard", "player123")
```

### Distributed Lock
```python
import time

def acquire_lock(lock_key, timeout=10):
    lock_id = str(uuid.uuid4())
    end = time.time() + timeout
    
    while time.time() < end:
        if redis_client.set(lock_key, lock_id, nx=True, ex=10):
            return lock_id
        time.sleep(0.001)
    
    return None

def release_lock(lock_key, lock_id):
    # Use Lua script for atomic check and delete
    script = """
    if redis.call("get", KEYS[1]) == ARGV[1] then
        return redis.call("del", KEYS[1])
    else
        return 0
    end
    """
    return redis_client.eval(script, 1, lock_key, lock_id)
```

### Real-time Analytics
```python
# Count unique visitors
redis_client.pfadd("visitors:2025-01-01", "user1", "user2", "user3")
count = redis_client.pfcount("visitors:2025-01-01")

# Track active users (HyperLogLog)
redis_client.pfadd("active:daily", user_id)
daily_active = redis_client.pfcount("active:daily")
```

### Message Queue
```python
# Producer
def enqueue_task(task_data):
    redis_client.rpush("task_queue", json.dumps(task_data))

# Consumer
def process_tasks():
    while True:
        # Blocking pop with timeout
        task = redis_client.blpop("task_queue", timeout=5)
        if task:
            _, task_data = task
            process_task(json.loads(task_data))
```

## Performance Optimization

### Pipeline (Batch Commands)
```python
# Without pipeline
for i in range(1000):
    redis_client.set(f"key:{i}", i)

# With pipeline (faster)
pipe = redis_client.pipeline()
for i in range(1000):
    pipe.set(f"key:{i}", i)
pipe.execute()
```

### Connection Pooling
```python
import redis

pool = redis.ConnectionPool(
    host='localhost',
    port=6379,
    max_connections=50,
    decode_responses=True
)

redis_client = redis.Redis(connection_pool=pool)
```

## Monitoring

### Info Command
```bash
INFO                            # All sections
INFO server                     # Server info
INFO memory                     # Memory usage
INFO stats                      # Statistics
INFO replication                # Replication status
INFO cpu                        # CPU usage
```

### Slow Log
```bash
# Get slow queries
SLOWLOG GET 10

# Get slow log length
SLOWLOG LEN

# Reset slow log
SLOWLOG RESET
```

### Monitor (Debug Only)
```bash
MONITOR                         # Show all commands in real-time
```

## Common Interview Questions

**Q: What is Redis?**
- In-memory data structure store
- Key-value database
- Cache, message broker, queue
- Extremely fast (sub-millisecond latency)

**Q: Why is Redis so fast?**
- In-memory storage (RAM)
- Simple data structures
- Single-threaded (no context switching)
- Efficient implementation in C

**Q: Redis vs Memcached?**
- Redis: Multiple data structures, persistence, replication
- Memcached: Only key-value strings, no persistence
- Redis more feature-rich, Memcached simpler

**Q: What are Redis data structures?**
- Strings, Lists, Sets, Sorted Sets, Hashes
- Bitmaps, HyperLogLogs, Streams
- Each optimized for specific use cases

**Q: How does Redis persistence work?**
- RDB: Point-in-time snapshots
- AOF: Log of every write operation
- Can use both for maximum durability

**Q: What is Redis replication?**
- Master-slave architecture
- Asynchronous replication
- Slaves can serve read queries
- Automatic failover with Sentinel

**Q: Explain Redis transactions**
- MULTI/EXEC for grouping commands
- All-or-nothing execution
- WATCH for optimistic locking
- Not ACID in traditional sense

**Q: What is Redis Cluster?**
- Automatic sharding across nodes
- High availability
- Linear scalability
- Hash slots (16384) distribution

**Q: How to handle cache invalidation?**
- TTL for automatic expiration
- Manual deletion on updates
- Lazy eviction policies
- Cache stampede prevention

**Q: What are Redis eviction policies?**
- noeviction: Return error when memory full
- allkeys-lru: Evict least recently used keys
- volatile-lru: Evict LRU keys with TTL
- allkeys-random: Random eviction
- volatile-ttl: Evict keys with shortest TTL

**Q: Use cases for Redis?**
- Caching (most common)
- Session storage
- Real-time analytics
- Rate limiting
- Leaderboards
- Message queues
- Pub/Sub messaging

**Q: What is Redis Sentinel?**
- High availability solution
- Monitors master and slaves
- Automatic failover
- Configuration provider for clients
